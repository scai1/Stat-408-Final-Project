---
title: "Stat 408 Final Project"
author: "Stone Cai"
date: "2024-03-23"
output:
  pdf_document: default
  html_document: default
---
Introduction

As someone pursuing a masters in applied statistics with the goal of a career change, it is an intriguing to question the career opportunities available after finishing this degree. What kind of salary and compensation can one expect if pursuing a career in data science/data analyst,etc? For this final project, I am considering a ds_salaries dataset which tracks the salaries of n= 3755 data science related careers from the years 2020-2023. I hope to get a general sense of the salaries and compensation expectations of data science related careers. Additionally, I hope to answer questions such as which factors/attributes are significant contributors to overall salary? What is the best model from among the dataset's variables that best explains salary expectations? On a surface level, are there are any predictors in the intial dataset that are redundant or collinear?  

To approach this problem, I am dividing this report into these sections:

1. Data Exploration and Preparation.  
2. Model Building+ Selection
3. Model refinement (Identifying outliers and checking influenceplots)
4. Interpretation of Results 
5. Evaluation and discussion. 



Section 1: Data Cleaning and Collapsing Variables
Here, I am going to recode, clean, and collapse variables appropriately in a way that will allow me to do analysis as I see fit.
```{r }

salary<- read.csv("C:/Users/stone/Documents/Stat 408/Final Project/ds_salaries.csv")

View(salary)

summary(salary)
##print(salary[order(salary$salary_in_usd, decreasing = TRUE), ]   )

```
Here, I have entered the data science salaries data set. From the initial summary of the dataset, I will determine how I need to clean data and re-code certain columns that I may want to use as predictors in a linear model. Here, I summarize the variables from the data card for the data set. 

1.work_year:	The year the salary was paid.

2.experience_level:	The experience level in the job during the year with the following possible values: (EN) Entry-level / Junior (MI) Mid-level / Intermediate (SE) Senior-level / Expert (EX) Executive-level / Director.

3.employment_type:	The type of employment for the role: PT: Part-time FT: Full-time CT: Contract FL: Freelance.

4.job_title:	The role worked in during the year.

5.salary:	The total gross salary amount paid.

6.salary_currency:	The currency of the salary paid as an ISO 4217 currency code.

7.salary_in_usd:	The salary in USD (FX rate divided by avg. USD rate for the respective year via fxdata.foorilla.com).

8.employee_residence:	Employee's primary country of residence in during the work year as an ISO 3166 country code.

9.Remote_ratio:	The overall amount of work done remotely, possible values are as follows: 
0= No remote work (less than 20%) 
50= Partially remote 
100= Fully remote (more than 80%).

10.company_location	The country of the employer's main office or contracting branch as an ISO 3166 country code.

11.company_size	The average number of people that worked for the company during the year: 
S= less than 50 employees (small)
M= 50 to 250 employees (medium) 
L= more than 250 employees (large)

From this initial summary I notice several issues.There are several potential redundant or irrelevant columns. As I've discussed in my introduction, I'm interested in data scientists' salary as the response variable and utilizing various predictors to determine what are the key factors that determines a data scientist's salary. Although it is nice to understand the currency that all employees in this data set are paid in, the variable salary_in_usd is the only relevant column because I can compare all the salaries in the same currency. Thus, I will remove both salary_currency and salary variables from the dataset, as the information is all contained within salary_in_USD. 

```{r }
salary1 <- subset( salary, select = -c(salary,salary_currency) )
##View(salary1)

table(salary1$work_year)
table(salary1$experience_level)
##table(salary1$job_title)

table(salary1$employment_type)
table(salary1$employee_residence)
table(salary1$remote_ratio)
table(salary1$company_location)
table(salary1$company_size)
```

Here, I'm identifying the counts of every variable in the data set so I can get an intial sense of what the data looks like and see how I can appropriately code factors for these variables. Here, I notice a few things. Most of the datasets' observations for work year fall into 2022 and 2023. Here, I have the option to to code as either a continuous or categorical variable. While over a larger a range of years,  I would intuitively recommend coding year as continuous, I know that inflation in this 4 year span was extremely anomalous. According to the federal reserve, inflation in 2020 was only 1.4% due to covid, while 2021 and 2022 were 7% and 6.5% respectively. Here, the wild swings in inflation are non-standard so I think it makes sense to code work_year as a categorical variable with 4 factors so as to compare salaries from each year as a category. Below, I go ahead and code all existing variables with their respective factors. 

```{r }
salary1$experience_level <- factor(salary1$experience_level)
levels(salary1$experience_level) <- c("EN", "Ex", "MI", "SE")

salary1$work_year <- factor(salary1$work_year)
levels(salary1$work_year) <- c("2020", "2021", "2022", "2023")

salary1$employment_type <- factor(salary1$employment_type)
levels(salary1$employment_type) <- c("CT", "FL", "FT", "PT")

salary1$remote_ratio <- factor(salary1$remote_ratio)
levels(salary1$remote_ratio)<- c("0", "50", "100" )

salary1$company_size <- factor(salary1$company_size)
levels(salary1$company_size)<- c("L", "M", "S" )

summary(salary1)

```
The last 3 variables I need to clean/ recode are job_title, company_location and employee_residence. For company_location and employee residence I'm looking to collapse and consolidate the variable into fewer categories. Given that most observations are from the "US", I believe it makes sense to collapse these variables into US, EU, and other so as to have enough observations for each cateogry and not have standard errors that are too large.  




```{r }

salary1[ , 'employee_residence1'] <- NA
salary1[ , 'company_location1'] <- NA



library(dplyr)

for(i in 1:length(salary1$employee_residence))
{ 
  if(salary1$employee_residence[i]=="CA" || salary1$employee_residence[i]=="US" )
  {
    salary1$employee_residence1[i] <- "US"
   
  }
  
   
 else if(salary1$employee_residence[i]== "ES" || salary1$employee_residence[i]== "DE" || salary1$employee_residence[i]== "AL"|| salary1$employee_residence[i]== "BA"|| salary1$employee_residence[i]== "BE"|| salary1$employee_residence[i]== "BG"|| salary1$employee_residence[i]== "CH"|| salary1$employee_residence[i]== "CZ"|| salary1$employee_residence[i]== "DK"|| salary1$employee_residence[i]== "EE"|| salary1$employee_residence[i]== "FI"|| salary1$employee_residence[i]== "FR"|| salary1$employee_residence[i]== "GB"|| salary1$employee_residence[i]== "GR"|| salary1$employee_residence[i]== "HR"|| salary1$employee_residence[i]== "HU"|| salary1$employee_residence[i]== "IE"|| salary1$employee_residence[i]== "IT"|| salary1$employee_residence[i]== "JE" || salary1$employee_residence[i]== "LT" || salary1$employee_residence[i]== "LU" || salary1$employee_residence[i]== "LV" || salary1$employee_residence[i]== "MD" || salary1$employee_residence[i]== "MK" || salary1$employee_residence[i]== "MT" || salary1$employee_residence[i]== "NL" || salary1$employee_residence[i]== "PL" || salary1$employee_residence[i]== "PT"|| salary1$employee_residence[i]== "RO"|| salary1$employee_residence[i]== "RS" || salary1$employee_residence[i]== "SE"|| salary1$employee_residence[i]== "SI" || salary1$employee_residence[i]== "SK" || salary1$employee_residence[i]== "TR"|| salary1$employee_residence[i]== "UA")
  
  {
    salary1$employee_residence1[i] <- "EU"
   
  }
  
 else
  {
    salary1$employee_residence1[i] <- "OT"
   
  }
  
  
}
  
######################### cleaning company_location data  

for(i in 1:length(salary1$company_location))
{ 
  if(salary1$company_location[i]=="CA" || salary1$company_location[i]=="US" )
  {
    salary1$company_location1[i] <- "US"
   
  }
  
   
 else if(salary1$company_location[i]== "ES" || salary1$company_location[i]== "DE" || salary1$company_location[i]== "AL"|| salary1$company_location[i]== "BA"|| salary1$company_location[i]== "BE"|| salary1$company_location[i]== "BG"|| salary1$company_location[i]== "CH"|| salary1$company_location[i]== "CZ"|| salary1$company_location[i]== "DK"|| salary1$company_location[i]== "EE"|| salary1$company_location[i]== "FI"|| salary1$company_location[i]== "FR"|| salary1$company_location[i]== "GB"|| salary1$company_location[i]== "GR"|| salary1$company_location[i]== "HR"|| salary1$company_location[i]== "HU"|| salary1$company_location[i]== "IE"|| salary1$company_location[i]== "IT"|| salary1$company_location[i]== "JE" || salary1$company_location[i]== "LT" || salary1$company_location[i]== "LU" || salary1$company_location[i]== "LV" || salary1$company_location[i]== "MD" || salary1$company_location[i]== "MK" || salary1$company_location[i]== "MT" || salary1$company_location[i]== "NL" || salary1$company_location[i]== "PL" || salary1$company_location[i]== "PT"|| salary1$company_location[i]== "RO"|| salary1$company_location[i]== "RS" || salary1$company_location[i]== "SE"|| salary1$company_location[i]== "SI" || salary1$company_location[i]== "SK" || salary1$company_location[i]== "TR"|| salary1$company_location[i]== "UA")
  
  {
    salary1$company_location1[i] <- "EU"
   
  }
  
 else
  {
    salary1$company_location1[i] <- "OT"
   
  }
  
  
}
  
##View(salary1)
table(salary1$employee_residence1)
table(salary1$company_location1)

salary2<- subset( salary1, select = -c(employee_residence,company_location) )
View(salary2)

```

First, I created a text document to match full country names to their 2 letter code names. (See attached .txt doucment in github). After, I match country names to their 2 letter code names, I determined which countries were part of Europe, US/Canada, and not either of the first 2. 

Here, I collapsed the variable of employee residence and company location. First, I create 2 new columns called employee_residence1 and company_location1 as I will append these re-coded values to these new columns. I combined Canada counts with US counts under "US". I believe fundamentally, Canadian tech companies function very similarly to the US, operate under the same language,etc. So even though I don't necessarily believe Canadian data science salaries are homogeneous to US data science salaries, I believe this makes more sense then coding  Canada as "Other".  I also collapsed all European countries into one EU factor and the remaining countries will fall under "OT" or other. From the frequency count after I re-coded both variables I believe this is a reasonable way to re-code the observations. Here, I believe I have enough observations for my standard errors to be reasonable for reach factor. I could further break down the remaining countries geographically, but I'm afraid I have too few observations for these new factors and thus have standard errors that are extremely large. I'm choosing to collapse the variables like this because  the vast majority of the ~3800 observations are from the US/Canada in both cases. Finally, I drop my original data frame columns from the re-coded dataframe.Note: One additional issue I believe I have here is multi-collinearity. The vast majority of people in this data set typically live in the same country as the Company that they work for. Obviously, these variables are not mirrored, but there's very likely some redundancy here. I will verify using a VIF calculation in a later section in this report, but I will likely have to drop either (employee_residence1 or company_location1) in my final model. 

```{r }

salary2$employee_residence1 <- factor(salary2$employee_residence1)
levels(salary2$employee_residence1)<- c("EU", "OT", "US" )

salary2$company_location1 <- factor(salary2$company_location1)
levels(salary2$company_location1)<- c("EU", "OT", "US" )

##summary(salary2)

```
In this step, I assign the appropriate factors for EU,OT. and US.

```{r }
##install.packages("tidytext")
library(tidytext)
library(tidyr)
library(dplyr)


salary2 %>% count(job_title, sort = TRUE)

job_frequency<-data.frame(table(unlist(strsplit(tolower(salary2$job_title), " "))))
##View(job_frequency)

sorted <- job_frequency[order(-job_frequency$Freq),]
View(sorted)
print (sorted)


```
Here, I am doing two separate tasks. First, I am tabulating most frequent job titles. Based on the table, we see Data Engineer, Data Scientist, Data Analyst, Machine Learning Engineer, Analytics Engineer, and Data Architect are the 5 most frequent job titles. I also took the job_title column a step further and found the highest frequency of a singular word in a job title. I also find that the words: data, engineer, scientist, analyst, and learning are most frequent word in a job title for this dataset. Based on these results, I believe I will end up coding top 5-7 words as indicator variables to see if having a specific word or "phrase" in the case of Machine Learning impacts one's salary. 

```{r }

salary2[ , 'employment_type1'] <- NA


for(i in 1:length(salary2$employment_type) )
{ 
  if(salary2$employment_type[i]=="FT")
  {
    salary2$employment_type1[i] <- "FT"
  }
  
  else
  {
    salary2$employment_type1[i] <- "PT"
  }
    
  
  }
##View(salary2)
##table( salary2$employment_type1)

salary3<- subset( salary2, select = -c(employment_type ))
View(salary3)

##table( salary3$employment_type1)

salary3$employment_type1 <- factor(salary3$employment_type1)
levels(salary3$employment_type1)<- c("FT", "PT" )

summary (salary3)

```
Here is another cleaning step I would like to conduct. Given that only 37 observations are not "full time", I want to collapse all other categories that are not "FT" into one a singular "PT" category thus effectively making this variable a binary categorical variable. 


Finally, I am going to create a variety of indicator variables that will represent whether a person's job title has a specific word or not. From the previous section where I broke down frequency of job titles and words in job titles, I found Data Engineer, Data Scientist, Data Analyst, Machine Learning Engineer, and Analytics Engineer were 5 most frequent job titles. This means I want to code data,engineer, scientist, analyst, machine learning, analytics, and manager as indicator variables to include in my model. Note for the 5 most common job titles, I would have to code as interaction terms. For example, data:engineer would only return 1 if both data and engineer are in title aka Data Engineer.  

```{r }

salary3[ , 'data_ind'] <- NA
salary3[ , 'engineer_ind'] <- NA
salary3[ , 'scientist_ind'] <- NA
salary3[ , 'analyst_ind'] <- NA
salary3[ , 'ML_ind'] <- NA
salary3[ , 'analytics_ind'] <- NA
salary3[ , 'manager_ind'] <- NA

##View(salary3)


##DATA INDICATOR VARIABLE

for(i in 1:length(salary3$job_title) )
{
  
  if(grepl("DATA", salary3$job_title[i] , ignore.case = TRUE ) )
  {
    salary3$data_ind[i] <- 1
  }
  
  else
  {
    salary3$data_ind[i] <- 0
  }
    
}
 ## View( salary3)

  
##Engineer Indicator Variable

  for(i in 1:length(salary3$job_title) )
{
  
  if(grepl("Engineer", salary3$job_title[i] , ignore.case = TRUE ) )
  {
    salary3$engineer_ind[i] <- 1
  }
  
  else
  {
    salary3$engineer_ind[i] <- 0
  }
    
}
  


##Scientist Indicator Variable

  for(i in 1:length(salary3$job_title) )
{
  
  if(grepl("Scientist", salary3$job_title[i] , ignore.case = TRUE ) )
  {
    salary3$scientist_ind[i] <- 1
  }
  
  else
  {
    salary3$scientist_ind[i] <- 0
  }
    
}
 


##Analyst Indicator

  for(i in 1:length(salary3$job_title) )
{
  
  if(grepl("Analyst", salary3$job_title[i] , ignore.case = TRUE ) )
  {
    salary3$analyst_ind[i] <- 1
  }
  
  else
  {
    salary3$analyst_ind[i] <- 0
  }
    
}
 
##Machine Learning Indicator

  for(i in 1:length(salary3$job_title) )
{
  
  if(grepl("Machine Learning", salary3$job_title[i] , ignore.case = TRUE )  || grepl("ml", salary3$job_title[i] , ignore.case = TRUE )  )
  {
    salary3$ML_ind[i] <- 1
  }
  
  else
  {
    salary3$ML_ind[i] <- 0
  }
    
}
 
table( salary3$ML_ind)

  
##Analytics Indicator

  for(i in 1:length(salary3$job_title) )
{
  
  if(grepl("Analytics", salary3$job_title[i] , ignore.case = TRUE ) )
  {
    salary3$analytics_ind[i] <- 1
  }
  
  else
  {
    salary3$analytics_ind[i] <- 0
  }
    
}

##Manager Indicator

  for(i in 1:length(salary3$job_title) )
{
  
  if(grepl("Manager", salary3$job_title[i] , ignore.case = TRUE ) )
  {
    salary3$manager_ind[i] <- 1
  }
  
  else
  {
    salary3$manager_ind[i] <- 0
  }
    
}


View(salary3)


```

I believe I have cleaned my data as I have desired and will now move onto exploratory data analysis. 




Section 2: Exploratory Data Analysis.   
Here, I will dive into the response variable (Salary) and every potential predictor from my cleaned dataset Salary3.I am looking to get a visual representation of salary based on the groups within each  predictor variable. 

```{r }
library(dplyr)
hist (salary3$salary_in_usd,  xlab = 'Salary (USD)', ylab = 'Frequency', main = 'Distribution of Data Science Salaries')
sort (boxplot(salary3$salary_in_usd, ylab= "Salary (USD)", main= "Boxplot of Salary" )$out )
summary( salary3$salary_in_usd)




```
Here we have histogram and boxplot of overall Salary. Our 5 point summary statistic shows mean and median of 135,000 USD and 137,570 USD respectively.The histogram shows overall right skew suggesting that there are few instances in which salaries are very high, but the majority of observations are below 200,000. I performed a sort of boxplot outliers and found those ranged from 297,300-450,000 USD. Additionally, the boxplot confirms a right skew. The boxplot suggests that there are up to 64 outliers based on salary alone. For now, I suspect that these large salaries reflect positions of senior executive positions. In my initial model selection, I will include all outliers. In section 4, I will delve deeper into identifying outliers and seeing if keeping or removing outliers produces a better model.    



```{r }

##boxplots of individual
boxplot(salary_in_usd ~ work_year, data = salary3, col = "red", xlab = 'Work Year', ylab = 'Salary(USD)', main = 'Boxplot of Salary by Work Year')

```
This boxplot of work_year confirms many of my intuitions about salaries with each passing year. Here, we see the first quartile, median value, and third quartile salaries increasing for each year. The maximum value of "non-outlier" observations for each year are also increasing. In general, there does seem to be some kind of inflation effect happening. Each year continues to have outliers in roughly the same range. In section 4, I will try to quantify to see if these outliers are mostly attributable to those in executive engineer positions.   


```{r }

##boxplots of individual predictors
boxplot(salary_in_usd ~experience_level, data = salary3, col = "red", xlab = 'Experience Level', ylab = 'Salary(USD)', main = 'Boxplot of Salary by Experience')


```
Here, we have a boxplot of salaries grouped by experience level. We see that the interquartile ranges for each experience level does follow as one expects. Entry level has the lowest IQ range, followed by Mid Level, Senior Engineer, and then executive. One would expect that more experience correlates to a higher salary and this trend seems true on a surface level. However, we also see that there are instances of Mid level and Senior Engineer positions that compensation in the same range as very high executive. This suggests that research field and job title may actually contribute to salary more than I expected as there may be certain fields/ job titles with very lucrative compensation even if it is not a executive level position. 

```{r }
##exploratory data analysis for Job Title


```

```{r }
##boxplot of remote_ratio
boxplot(salary_in_usd ~remote_ratio, data = salary3, col = "red", xlab = 'Remote Ratio', ylab = 'Salary(USD)', main = 'Boxplot of Salary by Remote Ratio')

```
Recall 0= no remote work whereas 100= Fully remote. On a surface level, it seems those who work remotely and in office have a fairly similar interquartile distribution and overall similar number of outliers on the higher end of salary ranges. However, it does seems that the no remote group has a narrower interquartile region. Those who work at a hybrid remote Company seem to have lower salaries based on median and interquartile values. 

```{r }
##boxplot of Company size
boxplot(salary_in_usd ~company_size, data = salary3, col = "green", xlab = 'Company Size', ylab = 'Salary(USD)', main = 'Boxplot of Salary by Company Size')

```
Here, on a surface level, seems that the distributions Company size seem to differ from each other. Those work at small companies have the lowest median+ interquartile range salaries. Additionally, even the outliers for this group have smaller salaries than the outliers of other groups. Next, the "Large" company group has the second highest median and interquartile range salaries. Additionally, the outliers in this group have higher salaries than those in the small group.Finally, it does seem the Medium Company group has the largest median and interquartile salaries among the 3 groups. The maximum "non-outlier" observation for the Large and Medium group are similar as well. Recall that we did determine that most observations in this data set (3153/3755) fall in the "Medium" category. 
```{r }
##boxplot of Company size
boxplot(salary_in_usd ~company_location1, data = salary3, col = "blue", xlab = 'Company Location', ylab = 'Salary(USD)', main = 'Boxplot of Salary by Company Location')

```
Here, a boxplot based on Company Location shows us that salries for the US+Canada are much higher than in Europe and the rest of the world. The median and interquartile salaries for this group is higher than the 2 other groups. Additionally, the maximum "non-outlier" salary in this group is higher as well. It does also seem that salaries for Companys in Europe are still higher than the rest of the world ( excluding US+Canada). This boxplot suggests there may be a meaningful relationship between salary and  Company location. I also notice that most high "Outlier" salaries for EU and OT fall well within the non-outlier maximum range for the US group. 

```{r }
##boxplot of Company size
boxplot(salary_in_usd ~employment_type1, data = salary3, col = "brown", xlab = 'Employment Type', ylab = 'Salary(USD)', main = 'Boxplot of Salary by Employment Type')

```
This boxplot doesn't necessarily offer us much insight. The part time group only has 37 observations and intuitively, those who work part time are paid less than full time employees because they are working less. The distribution of salaries for these groups confirms  this fact. 


```{r }
##boxplot of data indicator
boxplot(salary_in_usd ~data_ind, data = salary3, col = "brown", xlab = 'Data Indicator', ylab = 'Salary(USD)', main = 'Boxplot of Salary by Data Indicator')

```   
Here, the boxplot of salaries by Data Indicator variables suggests that the interquartile range and median value of those without data in their job title have higher salaries than those with data in their salaries. However, the group with data in job title has much larger sample size and contains way more of the higher "outlier"  salaries. 
```{r }
##boxplot of Engineer indicator
boxplot(salary_in_usd ~engineer_ind, data = salary3, col = "brown", xlab = 'Engineer Indicator', ylab = 'Salary(USD)', main = 'Boxplot of Salary by Engineer Indicator')

```  
Here, the boxplot of the engineer indicator variables shows that the interquartile ranges and median values for engineer vs non-engineer are very similar. However, the non-engineers seem to have the outlier large salaries. It is possible that engineers are by nature a medium to senior level position, and precludes the group from having manager/executive level positions which may explain why the outlier high salaries are much less frequent in the engineer group. 

```{r }
##boxplot of Manager indicator
boxplot(salary_in_usd ~manager_ind, data = salary3, col = "brown", xlab = 'Manager Indicator', ylab = 'Salary(USD)', main = 'Boxplot of Salary by Manager Indicator')

```  
This boxplot is somewhat suprising. I expected those with manager in their title to have more executive roles since they would be directly in charge of others. I thought this would correspond to some of the higher salaries, but evidently the manager group didn't have any observations among the highest earning salaries in the dataset.This might manifest itself when I model the variable.  



```{r }
##boxplot of Data+Engineer interaction
boxplot(salary_in_usd ~data_ind:engineer_ind, data = salary3, col = "brown", xlab = 'Data Engineer Interaction', ylab = 'Salary(USD)', main = 'Boxplot of Salary by Data-Engineer Interaction')

```   
This is a boxplot of the interaction between Data indicator and Engineer indicator variable. The 1.1 group is the "Data Engineer" group. I notice the interquartile range is very small for this group as if to suggest that salaries for this group are very clustered. There are very few outliers in this group and even then, their salaries aren't necessarily large compared to the entire dataset.It is possible that data engineer is very much a "mid-level" position and the boxplot distribution suggests that.  

I will not present boxplot for every indicator variable/ interaction combination. I just wanted to explore the indicators with most frequent occurrences. 


Section 3: Model Building+ Selection. 
Here, I am going to build the best possible model based on the predictors within this data set. I will still include a full model for reference and compare that to the best model I determine from stepwise selection. 
```{r }
library(MASS)
library(car)
model_full<- lm (salary_in_usd~work_year+experience_level+remote_ratio+company_size+employee_residence1+company_location1+employment_type1+data_ind+engineer_ind+
                   scientist_ind+ analyst_ind+ML_ind+analytics_ind+ manager_ind, data= salary3)

vif(model_full)

```
Here, one of my first biggest suspicion was that employment_type1 and Company_location1 were too similar and  would cause issue of collinearity. A vif test shows that both are above 10 so i need to remove one of them from my model. I will remove employee location as Company location is slightly more important since the Company is paying their workers. 


```{r }

model_full1<- lm (salary_in_usd~work_year+experience_level+remote_ratio+company_size+company_location1+employment_type1+data_ind+engineer_ind+
                   scientist_ind+ analyst_ind+ML_ind+analytics_ind+ manager_ind, data= salary3)

model_full2<- lm (salary_in_usd~work_year+experience_level+remote_ratio+company_size+company_location1+employment_type1+data_ind+engineer_ind+
                   scientist_ind+ analyst_ind+ML_ind+analytics_ind+ manager_ind+ data_ind:engineer_ind+ data_ind:scientist_ind+ data_ind:analyst_ind + ML_ind:engineer_ind+ 
                    analytics_ind:engineer_ind, data= salary3)





plot(model_full2)
summary(model_full2)

```
Here before I move onto model building through AIC stepwise selection, I need to check my regression assumptions and see if the response variable needs any transformation. 
Looking at the regression diagnostic plot, I notice issues in every diagnostic plot. The residuals vs fitted plot is exhibiting classic fanning where there residuals grow larger as the fitted salaries get larger. This violates our assumption of homoskedacity. For the QQplot I notice there is heavy right tail in the normality plot (which we already suspect from our histogram plot). This does makes sense as in any industry, those with the highest paying salaries have disproportionately higher salaries than others. Finally, the scale vs location plot is nowhere near horizontal slope. It starts at 0.5 studentized residual distance and ends at 0.8. Finally, if I look at the full modeled I constructed, I have every single indicator variable and then 5 interaction variables between the indicators that represent the 5 most frequently occurring job (i.e Data Engineer or Data Analyst). Here, I notice that all 3 factors of experience level seem to be significant, small company size, company being in the US, employment type, scientist_ind, and the interaction terms data engineer and data scientist seem to be significant predictors in the full model. $R^2$ is fairly low at 0.4004 and adjusted $R^2$ is also low due to the penalty of having so many predictors. In class, for very heavy right skew models we utilized a log transformation on our response variable so as to "scale" and reduce the weight that very high salary outliers would have on the model. 

```{r }

log_fullmodel<- lm ( log(salary_in_usd)~work_year+experience_level+remote_ratio+company_size+company_location1+employment_type1+data_ind+engineer_ind+
                   scientist_ind+ analyst_ind+ML_ind+analytics_ind+ manager_ind+ data_ind:engineer_ind+ data_ind:scientist_ind+ data_ind:analyst_ind + ML_ind:engineer_ind+ 
                    analytics_ind:engineer_ind, data= salary3)




plot(log_fullmodel)
summary(log_fullmodel)

salary3[ , 'log_salary'] <- NA
##View(salary3)

salary4 <- transform(salary3, log_salary = log(salary_in_usd))
View(salary4)

```
Here,I create another column in my data frame so as to obtain log values for salary_in_USD and then regress the full model of the transformed response variable. I look at the regression plot once more and I see improvement in the residuals vs fitted graph. The issues of fanning out is resolved and I would say the assumption of homoskedacity is met here. The QQ plot seems to have made things only slightly better as now there are skews on both tails, but is at least  symmetric. Scale vs location plot doesn't seem to have improved at all. However, a vast majority of observations are within the 11.5-12.0 fitted values range, the red line in that range doesn't really jump studentized residual range (0.7-0.6) and most of the issues of this diagnostic plot lies within the range with much fewer observations. One can consider this graph marginally better. These plots may improve once I've found a simpler and final model. Finally, the adjusted  $R^2$ of the transformed model is meaningfully better at 0.52 vs 0.40. So I believe the log transformation of my response variable is correct. 
```{r }

backward<- lm ( log_salary~work_year+experience_level+remote_ratio+company_size+company_location1+employment_type1+data_ind+engineer_ind+
                   scientist_ind+ analyst_ind+ML_ind+analytics_ind+ manager_ind+ data_ind:engineer_ind+ data_ind:scientist_ind+ data_ind:analyst_ind + ML_ind:engineer_ind+ 
                    analytics_ind:engineer_ind, data= salary4)


buildBackward<-stepAIC(backward,direction="backward")

summary(buildBackward)
vif(buildBackward)


```
Here, I run a first initial backward selection using the StepAIC method. Here, at each step I'm trying to remove a predictor so as to decrease overall AIC of the model, until I reach the smallest AIC value. Here, I then summarize the "best model" that the backward function finds. Here, the adjusted $R^2$ remains essentially unchanged at 0.52.Some of the interaction terms are significant such as Data:Engineer and Data:scientist.Additionally, some of the indicators such as scientist and engineer are significant. However, when I run another VIF test of this model, I realize there are several issues with VIF  and they all seem to relate to using both the indicator variables and their interaction terms together in the same model. Every VIF above 10 indicates issues of col linearity. First, I'm going to remove data_ind and analyst_ind as they were non-significant predictors and see if the VIF of that particular model has fewer issues. 

```{r }

VIF_model1<-lm(formula = log_salary ~ work_year + experience_level + company_size + 
    company_location1 + employment_type1  + engineer_ind + 
    scientist_ind  + analytics_ind + manager_ind + 
    data_ind:engineer_ind + data_ind:scientist_ind + data_ind:analyst_ind, 
    data = salary4)

summary(VIF_model1)
vif (VIF_model1)

```
Here I think ive found best model..........


INTERPRETATION: SPEND A COUPLE PARAGRAPHS HERE









Section 4

```{r }

influencePlot(VIF_model1)

print(salary4[3676,])
print(salary4[2129,])
print(salary4[3722,])
print(salary4[184,])
print(salary4[3668,])
print(salary4[2685,])


```






Section 5: Evaluation and discussions 

Overall, there are many constraints that limit the extent we can draw conclusions and model build. 1) I'm only able to include predictors that were available to me within the data set. Even more, I showed that several of these predictors/ response variable were ultimately redundant or had issues of multi-collinearity. 2) My entire model only consists of categorical and indicator variables. Ideally, I  would have preferred to have some continuous predictors within my model. A couple that come to mind are years of experience, number of software certifications,etc. Maybe another important categorical variable is level of education. Although there is no telling if these predictors would necessarily improve the model, they are definitely worth exploring and would alter the strength of my best regression model. 3) A final limitation of the data set were that despite having a large sample size, a lot of a observations were still heavily concentrated around certain categories. I.e a vast majority of observations for Company location were clustered around the US or there were ~1% of the sample that was part time. There may be underlying limitations to which the data was sampled and collected. 


The model I ultimately determined, is a fairly strong model in that I  tried to eliminate collinaerity between predictors and the predictors I included in final model were all significant.The final model did have a reasonable strong adjusted $R^2$. However, some of my regression plots even with a transformed response variables still demonstrated some issues. Obviously, in a real life data set, regression assumptions cannot be perfect and small issues may still exist no matter how hard statisticians try to address them. However, I still believe there may be some limitations as I was not able to fully correct them within the scope of this paper. 




If I had more time, I would have attempted to delve deeper into the job title indicators that I created. 





